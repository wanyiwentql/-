<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<title>Nvidia</title>
	<style type="text/css">
		
	ul li{
			list-style: none;
			float: left;
			width: 25%;
			text-align: center;
			padding-top: 8px;
			padding-bottom: 8px;
			background-color:black ;
			background-color:rgb(50,50,50) ;

		}
		a{
			text-decoration: none;
			color: white;
		}
		.backgroound2{
			 margin-top:0px;
			 width:1500px;
			 height:2000px;
			 background-color: rgb(155,155,155);
			 background-image: url("Images/by-tira-owl-kosmos-tumannost-planety_2000x1500.jpg");
			 background-repeat: repeat;
			background-size: cover;
		 }
	.text{

		font-style: normal;
		font-size: 20px;
		font-family:"微软雅黑 light";
		color:white ;
		text-align: left;
	}
	.theme{
		color: lightgray;
		font-family:"微软雅黑";
		font-style: italic;
		font-size:30px;

	}
	.box{
		height: 300px;
		width: 600px;
	}
		.tn1{
			margin-top: 30px;
			float: inherit;
			background-image: url("Images/20180404155146016.jpg");
			background-size: contain;
		}
		.tn2{
			margin-top: 30px;
			float: inherit;
			background-image: url("Images/untitled000.png");

		}
		.tn3{
			margin-top: 30px;
			float: inherit;
			background-image: url("Images/20180815221117146.png");
			background-size: contain;

		}
		h3{
			color: white;
		}
	.backbutton{
		float: right;
	}
	.closebutton{border-radius: 300px;
		color: lightgray;
		float: left;

	}
		</style>
	
</head>
<body>
<div class="backgroound2">

<h3>研究方向</h3>
<br>
	<ul class="ul">
		<li><a href="kexue.html">Navidia加速数据科学</a></li>
		<li><a href="jiqiren.html">Robot</a></li>
		<li><a href="nongye.html">TensorRT</a></li>
		<li><a href="yiliao.html">Medical</a></li>
	</ul>
<br>
<br>
<br>
<p align="center" class="text theme"><strong>NVIDIA TensorRT 让您的人工智能更快！</strong>
<div class="box tn1"></div>
<p class="text">
英伟达TensorRT™是一种高性能深度学习推理优化器和运行时提供低延迟和高通量的深度学习推理的应用程序。使用TensorRT，您可以优化神经网络模型，精确地校准低精度，并最终将
模型部署到超大规模的数据中心、嵌入式或汽车产品平台。在对所有主要框架进行培训的模型的推理过程中，基于TensorRT的gpu应用程序的执行速度比CPU快100倍。
&nbsp&nbsp     TensorRT提供INT8和FP16的优化，用于深度学习推理应用程序的生产部署，如视频流、语音识别、推送和自然语言处理。减少推断精度可以大大降低了
应用程序的延迟，这是许多实时服务以及自动和嵌入式应用程序的需求。</p>
	<div class="box tn2"></div>
<p align="center" class="text theme"><strong>使用TensorRT集成加速TensorFlow推理</strong></p>
<p class="text">&nbsp &nbsp  NVIDIA宣布完成了推理优化工具TensorRT与TensorFlow将集成在一起工作。TensorRT集成将可用于TensorFlow1.7版本。TensorFlow仍然是当今最受欢迎的深度学习框架，而NVIDIA TensorRT通过对GPU平台的优化和提高性能，
加速了深度学习推理。我们希望使用TensorRT能为TensorFlow用户提供尽可能高的推理性能以及接近透明的工作流。新的集成提供了一个简单的API，它能够使用TensorFlow中的TensorRT实现FP16和INT8的优化。对于ResNet-50基准测试的低延迟运行，
TensorRT将TensorFlow推理速度提高了8倍。
<br>
&nbsp&nbsp</p>
	<div class="box tn3"></div>
<p align="center" class="text theme"><strong>基于TensorRT的神经网络推理与加速</strong></p>
 <p class="text">NVIDIA TensorRT是一种高性能神经网络推理(Inference)引擎，用于在生产环境中部署深度学习应用程序，应用于图像分类、分割和目标检测等，可提供最大的推理吞吐量和效率。TensorRT是第一款可编程推理加速器，能加速现有和未来的网络架构。TensorRT包含一个为优化生产环境中部署的深度
学习模型而创建的库，可获取经过训练的神经网络(通常使用32位或16位数据)，并针对降低精度的INT8运算来优化这些网络。借助CUDA的可编程性，
	 TensorRT可以大幅度加速，服务提供商能够以经济实惠的成本部署这些计算密集型人工智能工作负载。</p>
	<script>
        function back() {
            window.location.href=("index.html")
        }
	</script>
	<br>
	<br>
	<div class="backbutton" ><button type="back" onclick="back()" src="9790944_0.jpg">返回主页</button></div>
	<div class="closebutton"> <button type="close" onclick="window.close();">关闭网页</button>
	</div>
</div>

<!--<input type="checkbox" name="122">接受我们的条款-->
</body>
</html>